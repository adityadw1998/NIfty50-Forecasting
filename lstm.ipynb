{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Shares Traded</th>\n",
       "      <th>Turnover (Rs. Cr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-Dec-2016</td>\n",
       "      <td>8178.20</td>\n",
       "      <td>8178.70</td>\n",
       "      <td>8127.45</td>\n",
       "      <td>8139.45</td>\n",
       "      <td>209268331</td>\n",
       "      <td>9854.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19-Dec-2016</td>\n",
       "      <td>8126.00</td>\n",
       "      <td>8132.50</td>\n",
       "      <td>8094.85</td>\n",
       "      <td>8104.35</td>\n",
       "      <td>110669713</td>\n",
       "      <td>5272.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-Dec-2016</td>\n",
       "      <td>8110.60</td>\n",
       "      <td>8124.10</td>\n",
       "      <td>8062.75</td>\n",
       "      <td>8082.40</td>\n",
       "      <td>132026742</td>\n",
       "      <td>6296.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21-Dec-2016</td>\n",
       "      <td>8105.85</td>\n",
       "      <td>8112.55</td>\n",
       "      <td>8053.25</td>\n",
       "      <td>8061.30</td>\n",
       "      <td>127543733</td>\n",
       "      <td>6304.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Dec-2016</td>\n",
       "      <td>8043.85</td>\n",
       "      <td>8046.45</td>\n",
       "      <td>7964.95</td>\n",
       "      <td>7979.10</td>\n",
       "      <td>126409580</td>\n",
       "      <td>6206.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Open     High      Low    Close  Shares Traded  \\\n",
       "0  16-Dec-2016  8178.20  8178.70  8127.45  8139.45      209268331   \n",
       "1  19-Dec-2016  8126.00  8132.50  8094.85  8104.35      110669713   \n",
       "2  20-Dec-2016  8110.60  8124.10  8062.75  8082.40      132026742   \n",
       "3  21-Dec-2016  8105.85  8112.55  8053.25  8061.30      127543733   \n",
       "4  22-Dec-2016  8043.85  8046.45  7964.95  7979.10      126409580   \n",
       "\n",
       "   Turnover (Rs. Cr)  \n",
       "0            9854.07  \n",
       "1            5272.20  \n",
       "2            6296.67  \n",
       "3            6304.60  \n",
       "4            6206.58  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Shares Traded','Turnover (Rs. Cr)'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8178.20</td>\n",
       "      <td>8178.70</td>\n",
       "      <td>8127.45</td>\n",
       "      <td>8139.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8126.00</td>\n",
       "      <td>8132.50</td>\n",
       "      <td>8094.85</td>\n",
       "      <td>8104.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8110.60</td>\n",
       "      <td>8124.10</td>\n",
       "      <td>8062.75</td>\n",
       "      <td>8082.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8105.85</td>\n",
       "      <td>8112.55</td>\n",
       "      <td>8053.25</td>\n",
       "      <td>8061.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8043.85</td>\n",
       "      <td>8046.45</td>\n",
       "      <td>7964.95</td>\n",
       "      <td>7979.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open     High      Low    Close\n",
       "0  8178.20  8178.70  8127.45  8139.45\n",
       "1  8126.00  8132.50  8094.85  8104.35\n",
       "2  8110.60  8124.10  8062.75  8082.40\n",
       "3  8105.85  8112.55  8053.25  8061.30\n",
       "4  8043.85  8046.45  7964.95  7979.10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Date'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_test):\n",
    "    train_samples, train_nx, train_ny = X_train.shape\n",
    "    test_samples, test_nx, test_ny = X_test.shape\n",
    "    \n",
    "    X_train = X_train.reshape((train_samples, train_nx * train_ny))\n",
    "    X_test = X_test.reshape((test_samples, test_nx * test_ny))\n",
    "    \n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    \n",
    "    X_train = X_train.reshape((train_samples, train_nx, train_ny))\n",
    "    X_test = X_test.reshape((test_samples, test_nx, test_ny))\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix()\n",
    "    \n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index : index + sequence_length])\n",
    "        \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[: int(row), :]\n",
    "    \n",
    "    train, result = standard_scaler(train, result)\n",
    "    \n",
    "    X_train = train[:, : -1]\n",
    "    y_train = train[:, -1][: ,-1]\n",
    "    X_test = result[int(row) :, : -1]\n",
    "    y_test = result[int(row) :, -1][ : ,-1]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # By setting return_sequences to True we are able to stack another LSTM layer\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (206, 20, 4)\n",
      "y_train (206,)\n",
      "X_test (23, 20, 4)\n",
      "y_test (23,)\n"
     ]
    }
   ],
   "source": [
    "window = 20\n",
    "X_train, y_train, X_test, y_test = preprocess_data(df[:: -1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 4), return_sequences=True, units=20)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.01689434051513672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n"
     ]
    }
   ],
   "source": [
    "model = build_model([X_train.shape[2], window, 100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 185 samples, validate on 21 samples\n",
      "Epoch 1/300\n",
      "0s - loss: 0.8939 - acc: 0.0000e+00 - val_loss: 2.5244 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "0s - loss: 0.4653 - acc: 0.0000e+00 - val_loss: 1.8870 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "0s - loss: 0.2723 - acc: 0.0000e+00 - val_loss: 1.3422 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "0s - loss: 0.1455 - acc: 0.0000e+00 - val_loss: 0.8694 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "0s - loss: 0.0998 - acc: 0.0000e+00 - val_loss: 0.5874 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "0s - loss: 0.0813 - acc: 0.0000e+00 - val_loss: 0.4401 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "0s - loss: 0.0953 - acc: 0.0000e+00 - val_loss: 0.4396 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "0s - loss: 0.0903 - acc: 0.0000e+00 - val_loss: 0.4326 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "0s - loss: 0.1060 - acc: 0.0000e+00 - val_loss: 0.4740 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "0s - loss: 0.0868 - acc: 0.0000e+00 - val_loss: 0.3739 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "0s - loss: 0.0751 - acc: 0.0000e+00 - val_loss: 0.3633 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "0s - loss: 0.0729 - acc: 0.0000e+00 - val_loss: 0.3539 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "0s - loss: 0.0804 - acc: 0.0000e+00 - val_loss: 0.3156 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "0s - loss: 0.0823 - acc: 0.0000e+00 - val_loss: 0.4598 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "0s - loss: 0.0798 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "0s - loss: 0.0749 - acc: 0.0000e+00 - val_loss: 0.3631 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "0s - loss: 0.0868 - acc: 0.0000e+00 - val_loss: 0.2795 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "0s - loss: 0.0736 - acc: 0.0000e+00 - val_loss: 0.3722 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "0s - loss: 0.0880 - acc: 0.0000e+00 - val_loss: 0.1653 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "0s - loss: 0.0954 - acc: 0.0000e+00 - val_loss: 0.6103 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "0s - loss: 0.1192 - acc: 0.0000e+00 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "0s - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.4283 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "0s - loss: 0.0741 - acc: 0.0000e+00 - val_loss: 0.2074 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "0s - loss: 0.0758 - acc: 0.0000e+00 - val_loss: 0.3780 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "0s - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.2775 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "0s - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.2728 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "0s - loss: 0.0654 - acc: 0.0000e+00 - val_loss: 0.2325 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "0s - loss: 0.0662 - acc: 0.0000e+00 - val_loss: 0.3287 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "0s - loss: 0.0719 - acc: 0.0000e+00 - val_loss: 0.2620 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "0s - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.2673 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "0s - loss: 0.0726 - acc: 0.0000e+00 - val_loss: 0.3526 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "0s - loss: 0.0627 - acc: 0.0000e+00 - val_loss: 0.1601 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "0s - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.6491 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "0s - loss: 0.0916 - acc: 0.0000e+00 - val_loss: 0.1757 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "0s - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 0.4455 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "0s - loss: 0.0837 - acc: 0.0000e+00 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "0s - loss: 0.0756 - acc: 0.0000e+00 - val_loss: 0.5103 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "0s - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.1957 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "0s - loss: 0.0671 - acc: 0.0000e+00 - val_loss: 0.2321 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "0s - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.3461 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "0s - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "0s - loss: 0.0541 - acc: 0.0000e+00 - val_loss: 0.2345 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "0s - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.2624 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "0s - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 0.2382 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "0s - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.1627 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "0s - loss: 0.0555 - acc: 0.0000e+00 - val_loss: 0.2338 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "0s - loss: 0.0558 - acc: 0.0000e+00 - val_loss: 0.3043 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "0s - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.1121 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "0s - loss: 0.0632 - acc: 0.0000e+00 - val_loss: 0.3967 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "0s - loss: 0.0758 - acc: 0.0000e+00 - val_loss: 0.0954 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "0s - loss: 0.0898 - acc: 0.0000e+00 - val_loss: 0.6246 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "0s - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.2189 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "0s - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.2934 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "0s - loss: 0.0624 - acc: 0.0000e+00 - val_loss: 0.1767 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "0s - loss: 0.0601 - acc: 0.0000e+00 - val_loss: 0.2894 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "0s - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.2303 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "0s - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "0s - loss: 0.0561 - acc: 0.0000e+00 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "0s - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.4264 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "0s - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "0s - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.4081 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "0s - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.1922 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "0s - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 0.3536 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "0s - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.1410 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "0s - loss: 0.0577 - acc: 0.0000e+00 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "0s - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.2217 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "0s - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.2012 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "0s - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.2469 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "0s - loss: 0.0518 - acc: 0.0000e+00 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "0s - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.2674 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "0s - loss: 0.0575 - acc: 0.0000e+00 - val_loss: 0.0829 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "0s - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.3851 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "0s - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "0s - loss: 0.0523 - acc: 0.0000e+00 - val_loss: 0.3445 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "0s - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "0s - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "0s - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "0s - loss: 0.0478 - acc: 0.0000e+00 - val_loss: 0.4203 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "0s - loss: 0.0543 - acc: 0.0000e+00 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "0s - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.3023 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "0s - loss: 0.0548 - acc: 0.0000e+00 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "0s - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.3595 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "0s - loss: 0.0555 - acc: 0.0000e+00 - val_loss: 0.1002 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "0s - loss: 0.0647 - acc: 0.0000e+00 - val_loss: 0.4717 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "0s - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.1666 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "0s - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "0s - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "0s - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.2610 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "0s - loss: 0.0511 - acc: 0.0000e+00 - val_loss: 0.1798 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "0s - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.2001 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "0s - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.1153 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "0s - loss: 0.0501 - acc: 0.0000e+00 - val_loss: 0.2656 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0492 - acc: 0.0000e+00 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "0s - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.4151 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "0s - loss: 0.0606 - acc: 0.0000e+00 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "0s - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "0s - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.1245 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "0s - loss: 0.0496 - acc: 0.0000e+00 - val_loss: 0.2457 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "0s - loss: 0.0443 - acc: 0.0000e+00 - val_loss: 0.1622 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "0s - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.1416 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "0s - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.2589 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "0s - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 0.1139 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "0s - loss: 0.0586 - acc: 0.0000e+00 - val_loss: 0.2727 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "0s - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "0s - loss: 0.0478 - acc: 0.0000e+00 - val_loss: 0.4519 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "0s - loss: 0.0559 - acc: 0.0000e+00 - val_loss: 0.1565 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "0s - loss: 0.0515 - acc: 0.0000e+00 - val_loss: 0.2726 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "0s - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "0s - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.2212 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "0s - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "0s - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.3148 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "0s - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "0s - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "0s - loss: 0.0497 - acc: 0.0000e+00 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "0s - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.2035 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "0s - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.1728 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "0s - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "0s - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.1491 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "0s - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.1839 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "0s - loss: 0.0438 - acc: 0.0000e+00 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "0s - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.1365 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "0s - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "0s - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "0s - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.4030 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "0s - loss: 0.0515 - acc: 0.0000e+00 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "0s - loss: 0.0466 - acc: 0.0000e+00 - val_loss: 0.2541 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "0s - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0912 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "0s - loss: 0.0490 - acc: 0.0000e+00 - val_loss: 0.3231 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "0s - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0935 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "0s - loss: 0.0470 - acc: 0.0000e+00 - val_loss: 0.2410 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "0s - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.2023 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "0s - loss: 0.0425 - acc: 0.0000e+00 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "0s - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "0s - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "0s - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.2504 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "0s - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.1397 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "0s - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "0s - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "0s - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.3110 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "0s - loss: 0.0516 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "0s - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.3742 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "0s - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "0s - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.1909 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "0s - loss: 0.0470 - acc: 0.0000e+00 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "0s - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "0s - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.1969 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "0s - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0829 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "0s - loss: 0.0446 - acc: 0.0000e+00 - val_loss: 0.3253 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "0s - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "0s - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.1753 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "0s - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0971 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "0s - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.2617 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "0s - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "0s - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.2456 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "0s - loss: 0.0411 - acc: 0.0000e+00 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "0s - loss: 0.0492 - acc: 0.0000e+00 - val_loss: 0.4108 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "0s - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "0s - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.2367 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "0s - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "0s - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 0.1659 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "0s - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "0s - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.1925 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "0s - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.1599 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "0s - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "0s - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.3071 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "0s - loss: 0.0457 - acc: 0.0000e+00 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "0s - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.3196 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "0s - loss: 0.0458 - acc: 0.0000e+00 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "0s - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.2736 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "0s - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.1006 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "0s - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.2139 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "0s - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "0s - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.2350 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "0s - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "0s - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.2359 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "0s - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.1172 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "0s - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.3422 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "0s - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "0s - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.2359 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "0s - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "0s - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.2564 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "0s - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "0s - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.2190 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "0s - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0813 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.3130 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "0s - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "0s - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "0s - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "0s - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "0s - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.2367 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "0s - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "0s - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "0s - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "0s - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.2082 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "0s - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.1257 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "0s - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "0s - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "0s - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.2689 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "0s - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0833 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "0s - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.2503 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "0s - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "0s - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.2164 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "0s - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.1154 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "0s - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "0s - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.2724 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "0s - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "0s - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.2494 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "0s - loss: 0.0390 - acc: 0.0000e+00 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "0s - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.2977 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "0s - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.1008 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "0s - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.2152 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "0s - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "0s - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "0s - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "0s - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.1940 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "0s - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "0s - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.1991 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "0s - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "0s - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0881 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "0s - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "0s - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "0s - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.3402 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "0s - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "0s - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.2463 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "0s - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "0s - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.2586 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "0s - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.1004 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "0s - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.2444 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "0s - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.1000 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "0s - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.2240 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "0s - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0969 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "0s - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.2740 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "0s - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "0s - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.2589 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "0s - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.1041 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "0s - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.2089 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "0s - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "0s - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.2328 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "0s - loss: 0.0427 - acc: 0.0000e+00 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "0s - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.2195 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "0s - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.1163 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "0s - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.1573 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "0s - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "0s - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.1503 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "0s - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.1594 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "0s - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "0s - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "0s - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0639 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "0s - loss: 0.0461 - acc: 0.0000e+00 - val_loss: 0.3613 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "0s - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.1150 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "0s - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.1807 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "0s - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.1394 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "0s - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "0s - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "0s - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.1818 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "0s - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.1294 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "0s - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.2182 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "0s - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "0s - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "0s - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "0s - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.1978 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "0s - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0971 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "0s - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.2439 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "0s - loss: 0.0526 - acc: 0.0000e+00 - val_loss: 0.0471 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "0s - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.2870 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "0s - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.1236 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "0s - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.1696 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "0s - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "0s - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "0s - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "0s - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.1881 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "0s - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0633 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "0s - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.2692 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "0s - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0995 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "0s - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.2336 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "0s - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0875 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.1948 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "0s - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "0s - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "0s - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.1299 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "0s - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.1315 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "0s - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "0s - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "0s - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.2867 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "0s - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0768 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "0s - loss: 0.0433 - acc: 0.0000e+00 - val_loss: 0.3029 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "0s - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "0s - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "0s - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.1271 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "0s - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.1131 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "0s - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "0s - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "0s - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "0s - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0553 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "0s - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.2509 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "0s - loss: 0.0414 - acc: 0.0000e+00 - val_loss: 0.0864 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "0s - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "0s - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "0s - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.1042 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "0s - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.1228 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f262f1f81d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=768,\n",
    "    nb_epoch=300,\n",
    "    validation_split=0.1,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.03 MSE (0.16 RMSE)\n",
      "Test Score: 0.99 MSE (0.99 RMSE)\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = []\n",
    "ratio = []\n",
    "pred = model.predict(X_train)\n",
    "for u in range(len(y_test)):\n",
    "    pr = pred[u][0]\n",
    "    ratio.append((y_test[u] / pr) - 1)\n",
    "    diff.append(abs(y_test[u] - pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f262f189630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(pred, color='red', label='Prediction')\n",
    "plt2.plot(y_train, color='blue', label='Ground Truth')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
